{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install captum\n",
    "%pip install torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "import PIL.Image as Image\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchcam.methods import GradCAMpp\n",
    "from torchcam.utils import overlay_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "loader = transforms.Compose([transforms.Resize((416, 416)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "random_image_name = 'Aston Martin V8 Vantage Convertible 2012/02412.jpg' #mettre une vraie image random et intégrer l'explicabilité ici\n",
    "image = Image.open(os.path.join(path_test, random_image_name))\n",
    "\n",
    "img = loader(image).float()\n",
    "img = torch.autograd.Variable(img, requires_grad=True)\n",
    "img = img.unsqueeze(0)\n",
    "img = img.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image)\n",
    "\n",
    "output = model(img)\n",
    "output = F.softmax(output, dim=1)\n",
    "\n",
    "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "pred_label_idx.squeeze_()\n",
    "occlusion = Occlusion(model)\n",
    "\n",
    "attributions_occ = occlusion.attribute(img,\n",
    "                                       strides = (3, 8, 8),\n",
    "                                       target=pred_label_idx,\n",
    "                                       sliding_window_shapes=(3,15, 15),\n",
    "                                       baselines=0)\n",
    "\n",
    "attributions_occ = attributions_occ.squeeze().cpu().detach().numpy()\n",
    "\n",
    "_ = viz.visualize_image_attr(np.transpose(attributions_occ, (1,2,0)),\n",
    "                                      method=\"heat_map\",\n",
    "                                      sign=\"all\",\n",
    "                                      show_colorbar=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GradCAMpp(model) as cam_extractor:\n",
    "  # Preprocess your data and feed it to the model\n",
    "  out = model(img)\n",
    "  # Retrieve the CAM by passing the class index and the model output\n",
    "  activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n",
    "\n",
    "result = overlay_mask(image, to_pil_image(activation_map[0].squeeze(0), mode='F'), alpha=0.5)\n",
    "plt.imshow(result); plt.axis('off'); plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
